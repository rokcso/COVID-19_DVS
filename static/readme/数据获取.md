## 使用 urllib

主要方法：`request.urlopen()`

示例：

```python
from urllib import request

url = "http://www.baidu.com/"

header = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.51 Safari/537.36"
}

req = request.Request(url, headers = header)

res = request.urlopen(req)

print(res.geturl()) # 获取请求 URL 地址
print(res.getcode()) # 获取请求状态码
print(res.info()) # 获取响应头

html = res.read() # 获取「字节」形式的响应内容
html.decode("utf-8") # 以「utf-8」格式解码响应内容  
```

## 使用 requests

主要方法：`requests.get()`

示例：

```python
import requests

url = "http://www.baidu.com/"

heaser = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.51 Safari/537.36"
}

res = requests.get(url, headers = header)

print(res.encoding) # 查看编码类型
print(res.status_code) # 查看请求状态码
print(res.headers) # 查看响应头，如果没有 Content-Type，则默认 encoding = utf-8，否则以设置的 charset 为准，如果也没有设置 charset，则默认 encoding = ISO-8859-1
print(res.url)

res.encoding = "utf-8"

html = res.text
```

## beautifulsoup4 解析响应内容

> 将 HTML 文档转换成一个树形结构，每一个节点都是一个 Python 对象

主要方法：BeautifulSoup(html)

- 获取节点：find()、find_all()、select()
- 获取属性：attrs
- 获取文本：text

示例：

```python
from bs4 import BeautifulSoup
import requests

url = "http://wsjkw.sc.gov.cn/scwsjkw/gzbd/fyzt.shtml"
res = requests.get(url)
res.encoding = "utf-8"
html = res.text
soup = BeautifulSoup(html)
soup.find("h2").text
# soup.find("a").attrs # 节点属性，json 格式
a = soup.find("a")
a_attr = a.attrs
a_url = a_attr["href"] # /scwsjkw/gzbd01/2022/4/10/8ad745003f4d452eace23e132d64949b.shtml

new_url = ""http://wsjkw.sc.gov.cn" + a_url

new_res = requests.get(new_url)
new_res.encoding = "utf-8"
new_html = new_res.text
new_soup = BeautifulSoup(new_html)

context = soup.find("p")
```

## 使用 re 解析响应内容

主要方法：re.search(regex, str)

- 在 str 中查找满足条件的字符串，匹配不上就返回 None
- 对返回结果可以分组，在字符串内添加小括号以分离数据
  - groups()
  - group(index) # 返回指定分组内容

### 正则表达式

- ^ : 匹配行首
- $ : 匹配行尾
- * : 
- + :
- ? : 
- \d : [0-9]

示例：

```python
context = soup.find("p")

import re

# 定义正则表达式
patten = "新增确诊病例(\d+)例.*?新增治愈出院病例(\d+)例.*?新增疑似病例(\d+)例" # .* 是忽略任意字符，后面的 ? 表示非贪婪匹配（匹配越少越好）

res = re.search(patten, context.text)

print(res.groups()) # 匹配到的所有数据
print(res.group(0)) # 匹配到的完整内容本身
print(res.group(1)) # 匹配到的第一个数据值
print(res.group(1), res.group(2), res.group(3))
```

## 解析将 json 字符串数据

```python
import json

# 将 json 字符串数据处理成字典格式
res_json = json.loads(res.text)

# 查看 res.json 字典的所有 key
res_json.keys()

# 修改时间格式
import time

d = "2022.04.11"
dd = time.strptime(d, "%Y.%m.%d")
ddd = time.strptime("%Y-%m-%d", dd)

# 将数据存入字典
his_date = {}
his_date[ddd] = {"key1": variable1, "key2": variable2}

# 更新字典数据
his_date[ddd].update({{"key3": variable3, "key4": variable4}})

# 将数据存入列表
to_date = []
to_date.append([date1, date2, date3])
```

## Python 连接 MySQL 数据库

使用 `pymysql` 模块

1. 建立连接
2. 创建游标
3. 执行操作
4. 关闭连接

示例:

```python
import pymysql
import traceback # 用于追踪异常的模块包

# 建立连接
conn = pymysql.connect(host = "xxx.xx.xxx.xx", user = "username", password = "pw", db = "datebase_name")

# 创建游标对象,默认返回元组类型,确保数据不被修改
cursor = conn.cursor()

# SQL 操作语句
sql = "select * from table_name"

# 执行 SQL 语句
cursor.execute(sql)

# 获取查询结果
res = cursor.fetchall()

# 关闭游标
cursor.close()

# 关闭连接
conn.close()

# 向数据库插入数据
# 如果 SQL 查询带参数，则在 SQL 语句中使用 `%s` 进行参数占位
sql = "insert into table_name values (%s, %s, %s, %s, %s, %s, %s, %s, %s)"

# 执行 SQL
cursor.execute(sql, [time.strftime("%Y-%m-%d"), 10, 1, 2, 3, 4, 5, 6, 7])

# 提交事物，查询语句不需要
conn.commit()

# 关闭游标、连接
cursor.close()
conn.close()
```

通用方法定义：

```python
def get_conn():
  """
  创建连接、游标
  :return: 连接、游标
  """
  # 创建连接
  conn = pymysql.connect(host = "xxx.xx.xxx.xx", user = "username", password = "pw", db = "datebase_name", charset = "utf-8")

  # 创建游标
  cursor = conn.cursor()
  
  return conn, cursor

def close_conn():
  """
  关闭连接、游标
  :return:
  """
  if cursor:
    cursor.close()
  if conn:
    conn.close()
```

## 使用 selenium 爬取动态渲染的数据

selenium 是 Web 应用程序测试工具，需要安装浏览器以及对应驱动程序

> 浏览器驱动下载站：http://npm.taobao.org/mirrors/chromedriver/

1. 创建浏览器对象
2. 浏览器.get()
3. 浏览器.find()

示例：

```python
from selenium.webdriver import Chrome, ChromeOptions

url = "http://xxx.com"

# 创建浏览器对象
browser = Chrome()

# 请求 URL
browser.get(url)

# print(browser.page_source)

# 获取响应的元素
res = browser.find_elements_by_xpath("here is your xpath")
print(res.text)

# 模拟点击操作
# 获取目标对象
btn = browser.find_element_by_xpath("here is your xpath")

# 对目标对象执行点击操作
btn.click()

# 等待 1 秒，模拟真人，避免毫秒级点击响应
time.sleep(1)

# 关闭浏览器
browser.close()

# 不打开浏览器静默浏览，在创建浏览器时
# 实例化 Chrome 浏览器
option = ChromeOptions()
# 对该实例添加参数，实现「无头浏览器」
option.add_argument("--headless")
# 部署 Linux 时禁用「沙箱」
option.add_argument("--no-sandbox")
# 使用上诉 option 创建浏览器对象
browser = Chrome(options = option)
```

https://www.bilibili.com/video/BV177411j7qJ?p=9&spm_id_from=pageDriver

onetab：https://www.one-tab.com/page/ne09PRtJTo2GVSo-kZRodw